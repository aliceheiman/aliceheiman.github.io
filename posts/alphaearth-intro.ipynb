{
 "cells": [
  {
   "cell_type": "raw",
   "id": "a36be2c3",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"AlphaEarth: A Peek into the Potential of Geospatial Satelitte Embeddings\"\n",
    "author: \"Alice Heiman\"\n",
    "date: \"2025-08-09\"\n",
    "image: \"alphaearth-intro/embedding-vis.png\"\n",
    "categories: [Article]\n",
    "toc: true\n",
    "citation:                                   \n",
    "  url: https://aliceheiman.github.io/posts/alphaearth-intro\n",
    "bibliography: alphaearth-intro/references.bib\n",
    "csl: nature-publishing-group-vancouver.csl\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64da0375",
   "metadata": {},
   "source": [
    "![AlphaEarth Embeddings of a Point in Brazil, State of Mato Grosso](alphaearth-intro/embedding-vis.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a1e9ab",
   "metadata": {},
   "source": [
    "## Why AlphaEarth?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3297b50b",
   "metadata": {},
   "source": [
    "For millenia, humans have stared into the night sky curious about space - but quite recently we've gotten the tools to look back onto the Earth.\n",
    "\n",
    "However, the amount of data has become a challenge. In the 1970's, the Landsat 1-3 satelittes on-board storage capacity was 3.75 GB per orbit. Today, Landsat 7 and 8 collect 1,200 scenes, equivalent to 1 TB of data, every 24 hours @mtaylorImagingLandsatScience2016, adding 3 TB of landsat products @LandsatProjectStatistics2018.\n",
    "\n",
    "**AlphaEarth Foundations is Google DeepMind's latest geospatial foundational AI model trained to assimilate thousands of image bands**\n",
    "\n",
    "The model is trained on 3 billion individual image frames sampled from over 5 million locations globally @earthAIpoweredPixelsIntroducing2025. Some of the data bands include \n",
    "\n",
    "- Optical and thermal imagery\n",
    "- Radar data\n",
    "- 3D surface measurements\n",
    "- Climate properties\n",
    "- Gravity fields\n",
    "- Geo-located descriptive text\n",
    "- ...and more\n",
    "\n",
    "**Through training, the model can compress all of this data into 64 numbers for each 10mx10m location, ready for downstream analysis.**\n",
    "\n",
    "The Google DeepMind team open released the [Satellite Embedding V1 Dataset](https://developers.google.com/earth-engine/datasets/catalog/GOOGLE_SATELLITE_EMBEDDING_V1_ANNUAL), which contains annual 64-dimensional embeddings between 2017-2024 at a 10m resolution @SatelliteEmbeddingV1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58729d50",
   "metadata": {},
   "source": [
    "## What are Satellite Embeddings?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04255432",
   "metadata": {},
   "source": [
    "In essence, the thousands of data bands are compressed into 64 bands that together is called a **satellite embeddings**.\n",
    "\n",
    "![The 64 bands of the satellite embedding visualized for a point in Brazil.](alphaearth-intro/square-64-gray-numbers.png)\n",
    "\n",
    "You can think of the embeddings as new **satellite embedding coordinates** that locates each point on Earth on a 64-dimensional sphere. These embeddings are constructed such that similar points (such as locations with solar panels) have embeddings pointing to locations close together on the sphere, while different points (such as solar panels vs. forest) have embeddings that point to different locations on the sphere."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dea64c7",
   "metadata": {},
   "source": [
    "![Similar locations have satellite embeddings close together, while different locations have embeddings that point in different directions.](alphaearth-intro/SphereComparison.mp4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01361fc8",
   "metadata": {},
   "source": [
    "What's special is that the embeddings capture similarities and difference both across **space and time**.\n",
    "\n",
    "This means that it is possible to track changes in the same patch of land just by looking at the evolution of the embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23fff4a",
   "metadata": {},
   "source": [
    "![The same geographical point can get different satellite embeddings over time, making it possible to track changes over time.](alphaearth-intro/ArrowOnSphere.mp4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b873e804",
   "metadata": {},
   "source": [
    "The indication of similarity between two spatio-temporal locations is then the **angle between the satellite embedding coordinates**.\n",
    "\n",
    "A popular similarity metric is the **cosine similarity** score, taking the cosine of the angle between the vectors.\n",
    "\n",
    "$$\n",
    "\\cos(\\theta) = \\frac{\\mathbf{a} \\cdot \\mathbf{b}}{|\\mathbf{a}||\\mathbf{b}|}\n",
    "$$\n",
    "\n",
    "The embedding coordinates in the AlphaEarth Foundation Satellite Embeddings dataset have already been normalized to have **unit length** (a length of one). Therefore, the cosine similarity simplifies to just the dot product between the embedding vectors. This is very efficient to compute.\n",
    "\n",
    "$$\n",
    "\\cos(\\theta) = \\mathbf{a} \\cdot \\mathbf{b}\n",
    "$$\n",
    "\n",
    "Visualizing the cosine similarity, it is possible to highlight areas that are either very similar or very different."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f722cb",
   "metadata": {},
   "source": [
    "![The dot product between two satellite embedding vector coordinates measures the similarity between them.](alphaearth-intro/TwoArrowsOnSphere.mp4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a134cf49",
   "metadata": {},
   "source": [
    "## What can we use Satellite Embeddings for?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2017ce62",
   "metadata": {},
   "source": [
    "Since the satellite embeddings contain a combination of thousands of data layers, they contain very rich semantic information about the relationship between locations on Earth.\n",
    "\n",
    "In fact, AlphaEarth achieves state of the art results on many benchmarks, with the authors repororting on average 24% lower error rates compared to other models tested @AlphaEarthFoundationsHelps2025.\n",
    "\n",
    "Some downstream tasks highlighted by the authors include **similarity search**, **unsupervised clustering**, and **supervised classification** @earthAIpoweredPixelsIntroducing2025."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb18db20",
   "metadata": {},
   "source": [
    "![AlphaEarth Foundations and the Satellite Embedding Dataset enable several downstream tasks, such as similarity search, unsupervised clustering, and supervised classification](alphaearth-intro/tasks.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132da8c6",
   "metadata": {},
   "source": [
    "Moreover, what makes these embeddings so powerful is that they **support continuous time** @brownAlphaEarthFoundationsEmbedding2025.\n",
    "\n",
    "Traditional data products are discrete in time due to satellite only passing over a patch of land at discrete points in time. But AlphaEarth is trained to interpolate between these."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452e34a9",
   "metadata": {},
   "source": [
    "**These tasks can help with applications such as tracking deforestation and urban expansion, categorizing agricultural lands to aid in food security, and help model water resources.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12883507",
   "metadata": {},
   "source": [
    "## What are the limitations?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837c1238",
   "metadata": {},
   "source": [
    "The Satellite Embedding dataset still has its fair share of limitations, including:\n",
    "\n",
    "- **Less interpretable features**: The new 64 bands don't have a direct physical meaning. This means it can be hard to interpret predictions and feature importance.\n",
    "- **Only 2017-2024**: The V1 dataset only goes back to 2017, limiting studies going further back in time.\n",
    "- **Mostly land-focused**: Many original data sources have limited data over the ocean, also impacting the embeddings.\n",
    "- **Limited coverage at the poles**: The dataset also has limited quality around the poles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f67498f",
   "metadata": {},
   "source": [
    "## Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30c04c7",
   "metadata": {},
   "source": [
    "If you are curious to learn more, the Google DeepMind team has curated a [collection of excellent resources and tutorials](https://developers.google.com/earth-engine/tutorials/community/satellite-embedding-01-introduction).\n",
    "\n",
    "Moreover, the Google DeepMind team is [currenlty offering a series of small grants](https://forms.gle/DngGMyeZeqVGpRHLA) to researchers using the Satellite Embedding dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2ea727",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578d8547",
   "metadata": {},
   "source": [
    "The AlphaEarth Foundations geospatial foundation model marks a pivotal moment for geospatial analysis.\n",
    "\n",
    "I am very excited to explore the applications of this model!\n",
    "\n",
    "Take care! ðŸ¥³"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spinningup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
